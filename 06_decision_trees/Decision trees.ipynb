{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Деревья решений. Недо- и переобучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('data.npz')\n",
    "X,y = data[\"X\"],data[\"y\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "np.random.seed(1337)\n",
    "#train ,  test\n",
    "Xtr,Xts,Ytr,Yts = train_test_split(X,y,test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Графички"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.scatter(Xtr[:,0],Xtr[:,1],c=Ytr,cmap='spectral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Здравствуй, дерево\n",
    "\n",
    "У дерева классификации (DecisionTreeClassifier) есть несколько параметров:\n",
    "* criterion : как выбирать лучший признак - 'gini' или 'entropy' (по умолчанию gini).\n",
    "* max_depth :  максимальная глубина дерева (по умолчанию - не ограничено)\n",
    "* min_samples_split : минимальное количество примеров, которые можно делить дальше (по умолчанию 2)\n",
    "* min_samples_leaf : минимальное количество примеров в листе (по умолчанию 1).\n",
    "\n",
    "Сейчас все параметры установлены по умолчанию, но скоро это изменится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(Xtr,Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нарисуем цветом то, что мы выучили\n",
    "* Дальше следует большая-толстая функция, которая по сути вызывает дерево решений в каждой точке и рисует это на графике. Она сильно оптимизирована, поэтому трудночитаема - пока в неё можно просто поверить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def plot_decision_surface(clf,X,y,\n",
    "                          plot_step = 0.2,\n",
    "                          cmap='spectral',\n",
    "                          figsize=(12,8)\n",
    "                         ):\n",
    "    # Plot the decision boundary\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    n_classes = len(set(y))\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=cmap,alpha=0.5)    \n",
    "    y_pred = clf.predict(X)\n",
    "\n",
    "    # Plot the training points\n",
    "    plt.scatter(*X[y_pred==y].T,c = y[y_pred==y],\n",
    "                marker='.',cmap=cmap,alpha=0.5,label='correct')\n",
    "    plt.scatter(*X[y_pred!=y].T,c = y[y_pred!=y],\n",
    "                marker='x',cmap=cmap,s=50,label='errors')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.axis(\"tight\")\n",
    "    plt.legend(loc='best')\n",
    "    print \"Accuracy = \",accuracy_score(y,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Качество на обучающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_decision_surface(tree,Xtr,Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Качество на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_decision_surface(tree,Xts,Yts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чини его полностью!\n",
    "\n",
    "Попробуйте поменять параметры DecisionTreeClassifier, чтобы точность стала лучше.\n",
    " * Accuracy >= 0.72 - неплохой первый шаг\n",
    " * Accuracy >= 0.75 - уже лучше, но можно ещё поднажать\n",
    " * Accuracy >= 0.78 - вполне неплохо\n",
    " * Accuracy >= 0.8  - или офигенно или очень повезло\n",
    " \n",
    "[чтобы не мучиться, можно не переписывать всё, а исправлять код выше]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ансамбли\n",
    "\n",
    "После этого можно попробовать Random Forest\n",
    "\n",
    "```from sklearn.ensemble import RandomForestClassifier```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search\n",
    "\n",
    "__Бонусный квест -__ найти оптимальные параметры классификатора поиском по сетке.\n",
    "Можно написать скрипт, который будет самостоятельно перебирать наборы параметров и выбирать те, у которых в итоге лучше точность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "<your code here>\n",
    "\n",
    "final_model = <your_code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_decision_surface(final_model,Xts,Yts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Всё ещё переобучаемся\n",
    "\n",
    "Дерево классификации строится так, чтобы лучше __подогнаться__ под __обучающую выборку__.\n",
    "Сейчас __вы подгоняете__ параметры модели так, чтобы качество на __тестовой выборке__ было наибольшим.\n",
    "По сути, вы больше не можете считать, что качество на тесте - хорошая оценка реального качества, потому, что вы подгоняетесь под эту выборку.\n",
    "\n",
    "Как с этим бороться?\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "Например, можно выделить ещё одну \"совсем тестовую\" выборку, положить её под камень и не использовать при выборе гиперпараметров -- и оцениваться на ней только 1 раз, когда вы уже определились с моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
